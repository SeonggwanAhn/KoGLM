# KoGLM

## Environment

I used
- python==3.8.12
- torch==1.8.0
- Details are in the requirements.txt
- I didn't used (1) docker GLM authors used, (2) deepspeed

### I will make the README more detail soon...


GLM is a General Language Model pretrained with an autoregressive blank-filling objective and can be finetuned on 
various natural language understanding and generation tasks. 

Please refer to our paper for a detailed description of GLM:

[GLM: General Language Model Pretraining with Autoregressive Blank Infilling](https://arxiv.org/abs/2103.10360)


